\documentclass[final]{article}

\usepackage{APS360}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{float}          % for [H] positioning 
 
\title{Progress Report: Chest X-ray Classification with Deep Learning}

\author{%
  Misumi \& Matsudo \\
  1010062254, misumi.matsudo@mail.utoronto.ca\\
  \href{https://colab.research.google.com/drive/1YR7MrA37j0j3YRxJ4ux_SQ7mhkUE7Gxc?usp=sharing}{Link to Google Colab}\\
}

\begin{document}

\maketitle

\vspace{-0.5in}

\section{Brief Project Description}

This project develops a deep learning system for automated chest X-ray classification, targeting four pathological conditions: Cardiomegaly, Effusion, Pneumonia, and No Finding. The system addresses the critical need for automated diagnostic tools in healthcare systems facing resource constraints and high examination volumes.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\linewidth]{figure.png}
    \caption{Multimodal architecture: CNN for image encoding, metadata branch, fusion classifier, and output.}
    \label{fig:architecture}
\end{figure}

The objective is developing a neural network capable of distinguishing between diagnostic categories using chest X-ray images and patient metadata. Deep learning's hierarchical feature learning makes it ideal for capturing complex pathological patterns in medical images.

\section{Notable Contribution}

\subsection{Data Processing}

I utilized the NIH chest X-ray dataset containing over 112,000 images from 30,805 patients. The original 14 pathological categories were reduced to four clinically significant conditions (Cardiomegaly, Effusion, Pneumonia, No Finding) for focused analysis. Due to computational constraints, I selected a representative 1,000-sample subset maintaining original class distribution for efficient experimentation.

\subsubsection{Class Imbalance Analysis and Label Processing}

The dataset exhibits severe class imbalance typical of medical data. I implemented priority-based label processing (Pneumonia → Cardiomegaly → Effusion → No Finding) ensuring critical conditions take precedence. Final distribution: No Finding (93.0\%, 901), Effusion (4.8\%, 47), Cardiomegaly (1.5\%, 15), Pneumonia (0.6\%, 6). This 155:1 imbalance represents a challenging medical AI scenario requiring specialized techniques.

\subsubsection{Multimodal Data Integration}

I integrated patient metadata with image features using three clinical variables: \textbf{Age} (Z-score normalized, μ=50.2, σ=16.8), \textbf{Gender} (Male=1, Female=0), and \textbf{View Position} (PA=1, AP=0). This multimodal approach mimics clinical practice where radiologists consider demographics and technical parameters alongside visual findings.

\subsubsection{Advanced Preprocessing Pipeline}

Image preprocessing uses dual transforms: training includes resize (256×256), augmentation (15° rotation, ±10\% translation, color jittering, perspective distortion), crop (224×224), and normalization; validation/test applies conservative resize and normalization only. Augmentation parameters preserve pathological features while preventing anatomical distortion.

\subsection{Baseline Model}

The baseline uses ResNet18 with standard cross-entropy loss. Despite 91.95\% accuracy, it completely fails on minority classes (Cardiomegaly and Pneumonia F1=0.00) with macro F1=0.24. Table~\ref{tab:baseline} shows misleading accuracy reflecting dominant "No Finding" class (F1=0.96) while missing critical pathologies.

\begin{table}[h]
\centering
\caption{Baseline Model Performance Results}
\label{tab:baseline}
\begin{tabular}{lcccc}
\toprule
Class & Precision & Recall & F1-Score & Support \\
\midrule
Cardiomegaly & 0.00 & 0.00 & 0.00 & 15 \\
Effusion & 0.20 & 0.06 & 0.10 & 47 \\
No Finding & 0.93 & 0.99 & 0.96 & 901 \\
Pneumonia & 0.00 & 0.00 & 0.00 & 6 \\
\midrule
Accuracy & & & 0.92 & 969 \\
Macro Avg & 0.28 & 0.26 & 0.26 & 969 \\
Weighted Avg & 0.88 & 0.92 & 0.90 & 969 \\
\bottomrule
\end{tabular}
\end{table}

This highlights medical image classification's challenge: high accuracy from majority class prediction provides no clinical value for detecting critical pathologies.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{baseline_training_curves.png}
    \caption{Baseline model training and validation curves showing loss and accuracy over epochs. The model quickly overfits to the majority class.}
    \label{fig:baseline_curves}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{baseline_confusion_matrix.png}
    \caption{Baseline model confusion matrix demonstrating complete failure to detect minority classes (Cardiomegaly and Pneumonia).}
    \label{fig:baseline_confusion}
\end{figure}

\subsection{Primary Model}

To address baseline limitations, I developed a multimodal architecture integrating advanced techniques for imbalanced medical image classification, incorporating both visual and clinical metadata features.

\subsubsection{Technical Implementation}

The architecture has three pathways: (1) \textbf{Visual} - ResNet50 backbone (2048-dim features, final 40 parameters trained), (2) \textbf{Clinical} - MLP (3→64→32) with dropout (0.2, 0.1), (3) \textbf{Classifier} - five layers (2080→1024→512→128→4) with normalization and progressive dropout (0.3→0.2→0.1).

Class imbalance handling uses: \textbf{Dynamic loss weighting} (γ=1.5) via $(1-p_t)^γ$ modulation, \textbf{Disease-prioritized sampling} (3× pathology amplification), and \textbf{smoothed weighting} (α=0.6): $w_{smooth} = αw_{balanced} + (1-α)w_{uniform}$.

Optimization: AdamW (lr=0.0003, decay=0.01), plateau LR reduction (patience=5, factor=0.7), gradient clipping (norm=1.0), early stopping on macro F1-score.

\subsubsection{Performance Analysis}

The improved model shows significant gains despite accuracy dropping to 84.21\%, reflecting balanced classification rather than majority class bias. Macro F1-score improved from 0.24 to 0.43 (65\% improvement). Table~\ref{tab:improved} shows successful detection: Cardiomegaly (F1=0.37) and Pneumonia (F1=0.12) versus baseline's complete failure.

\begin{table}[h]
\centering
\caption{Improved Model Performance Results}
\label{tab:improved}
\begin{tabular}{lcccc}
\toprule
Class & Precision & Recall & F1-Score & Support \\
\midrule
Cardiomegaly & 0.30 & 0.47 & 0.37 & 15 \\
Effusion & 0.23 & 0.62 & 0.33 & 47 \\
No Finding & 0.96 & 0.86 & 0.91 & 901 \\
Pneumonia & 0.10 & 0.17 & 0.12 & 6 \\
\midrule
Accuracy & & & 0.84 & 969 \\
Macro Avg & 0.40 & 0.53 & 0.43 & 969 \\
Weighted Avg & 0.91 & 0.84 & 0.87 & 969 \\
\bottomrule
\end{tabular}
\end{table}

Clinically significant recall improvements: 47\% for Cardiomegaly and 17\% for Pneumonia, identifying nearly half of cardiac cases and notable pneumonia portion. This represents crucial progress toward viable clinical screening.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{improved_training_curves.png}
    \caption{Improved model training curves showing stable accuracy improvement. Validation loss variation \& rising occurs due to extreme class imbalance and focal loss dynamics.}
    \label{fig:improved_curves}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{improved_confusion_matrix.png}
    \caption{Improved model confusion matrix showing successful detection of minority classes compared to baseline's complete failure.}
    \label{fig:improved_confusion}
\end{figure}

The 65\% macro F1 improvement validates the multimodal approach, demonstrating deep learning's effectiveness for rare pathology detection. Previously undetectable conditions (Cardiomegaly: 0.00→0.37, Pneumonia: 0.00→0.12 F1) represent critical advancement toward clinically deployable AI diagnostic assistance, establishing feasibility for effective multiclass chest X-ray classification.

\end{document}